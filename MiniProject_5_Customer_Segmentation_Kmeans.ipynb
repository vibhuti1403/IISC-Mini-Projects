{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "another-optimum"
      },
      "source": [
        "# Advanced Certification Program in Computational Data Science\n",
        "\n",
        "##  A program by IISc and TalentSprint\n",
        "\n",
        "### Mini Project Notebook: Customer segmentation using clustering"
      ],
      "id": "another-optimum"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maritime-miami"
      },
      "source": [
        "## Learning Objectives"
      ],
      "id": "maritime-miami"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nljJR6CwfZN_"
      },
      "source": [
        "At the end of the experiment, you will be able to :\n",
        "\n",
        "* extract summary level insight from a given customer dataset.\n",
        "\n",
        "* handle the missing data and identify the underlying pattern or structure of the data.\n",
        "\n",
        "* create an unsupervised model that generates the optimum number of segments for the customer base\n",
        "\n",
        "* identify customer segments based on the overall buying behaviour\n"
      ],
      "id": "nljJR6CwfZN_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "surprising-uruguay"
      },
      "source": [
        "## Dataset"
      ],
      "id": "surprising-uruguay"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "interior-simple"
      },
      "source": [
        "The dataset chosen for this mini project is the Online Retail dataset. It is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.\n",
        "\n",
        "The dataset contains 541909 records, and each record is made up of 8 fields.\n",
        "\n",
        "To know more about the dataset : [click here](https://archive.ics.uci.edu/ml/datasets/Online+Retail)"
      ],
      "id": "interior-simple"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "infrared-olympus"
      },
      "source": [
        "## Information"
      ],
      "id": "infrared-olympus"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6yE5zbTj3Tm"
      },
      "source": [
        "**Clustering** is the task of grouping together a set of objects so that the objects in the same cluster are more similar to each other than to objects in other clusters. Similarity is a measure that reflects the strength of the relationship between two data objects.\n",
        "\n",
        "In the clustering calculation, K-Means is a very popular algorithm. In this analysis, this method is used to cluster the similar data items.\n",
        "\n",
        "In Retail and E-Commerce (B2C), and more broadly in B2B, one of the key elements shaping the business strategy of a firm is understanding of customer behaviour. More specifically, understanding the customers based on different business metrics: how much they spend (revenue), how often they spend (frequency), are they new or existing customers, what are their favorite products, etc... Such understanding in turn helps direct marketing, sales, account management and product teams to support customers on a personalized level and improve the product offering.\n",
        "\n",
        "Furthermore, segmenting customers into different categories based on similar/cyclical buying pattern over a period of 1 year helps the retail shops manage their inventory better, thereby lowering costs and raising revenues by placing the orders in sync with the buying cycles."
      ],
      "id": "d6yE5zbTj3Tm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih-oasWmdZul"
      },
      "source": [
        "## Problem Statement"
      ],
      "id": "ih-oasWmdZul"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfWGmjNHdZul"
      },
      "source": [
        "Perform customer segmentation for an Online Retail using an Unsupervised Clustering technique (K-Means)"
      ],
      "id": "qfWGmjNHdZul"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abstract-stocks"
      },
      "source": [
        "### Import Required packages"
      ],
      "id": "abstract-stocks"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "advisory-knowing"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "advisory-knowing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybY7HeobdZum",
        "cellView": "form"
      },
      "source": [
        "#@title Download the data\n",
        "!wget -qq https://cdn.iisc.talentsprint.com/CDS/MiniProjects/Online_Retail.zip\n",
        "!unzip -qq Online_Retail.zip"
      ],
      "id": "ybY7HeobdZum",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp4bF_GJdZuo"
      },
      "source": [
        "## Load the data"
      ],
      "id": "gp4bF_GJdZuo"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prerequisite-knock"
      },
      "source": [
        "data = pd.read_csv('/content/Online_Retail_Train.csv')\n",
        "data.head()"
      ],
      "id": "prerequisite-knock",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL-K9lnWD71d"
      },
      "source": [
        "data.shape"
      ],
      "id": "OL-K9lnWD71d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtV_KWBLUzRk"
      },
      "source": [
        "## Data Pre-processing (2 points)"
      ],
      "id": "vtV_KWBLUzRk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQrT5tx3dZuq"
      },
      "source": [
        "Explore the dataset by performing the following operations:\n",
        "\n",
        "* There is a lot of redundant data. Identify such data and take appropriate action.\n",
        "\n",
        "  **Hint:** refer to this [link](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html)\n",
        "\n",
        "* Most Invoices appear as normal transactions with positive quantity and prices, but there are some prefixed with \"C\" or \"A\" which denote different transaction types. Invoice starting with C represents cancelled order and A represents the Adjusted. Identify such data and take appropriate action.\n",
        "\n",
        "  **Hint:** Check the negative values in Quantity column for all cancelled orders\n",
        "\n",
        "* Handle the null values by dropping or filling with appropriate mean\n",
        "\n",
        "\n",
        "* Some of the transactions based on the `StockCode` variable are not actually products, but representing the costs or fees regarding to the post or bank or other tansactions. Find such data and handle it accordingly.\n",
        "\n",
        "  Hint:\n",
        "    - The transaction with `'POST' 'PADS' 'M' 'DOT' 'C2' 'BANK CHARGES'` as their `StockCodes` are considered as irrelevant transactions.\n",
        "\n",
        "* Identify the outliers in the UntiPrice and Quantity and handle them accordingly.\n",
        "\n",
        "  **Hint:** [link](https://kanoki.org/2020/04/23/how-to-remove-outliers-in-python/)\n",
        "\n",
        "* Create a DayOfWeek column using `InvoiceDate`, Hint: pd.to_datetime()\n",
        "\n",
        "**Note:** Perform all the above operations using a function to reuse and apply the same for test data."
      ],
      "id": "NQrT5tx3dZuq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIqHzKCOIcT4"
      },
      "source": [
        "# original dataframe for backup\n",
        "data_orig = data"
      ],
      "id": "MIqHzKCOIcT4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "advanced-dispute"
      },
      "source": [
        "# Identify the cancelled orders\n",
        "len(data[data.InvoiceNo.str[0] == 'C']), len(data[data.Quantity < 1 ])"
      ],
      "id": "advanced-dispute",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "european-discount"
      },
      "source": [
        "# Check the null values\n",
        "data.isna().sum()"
      ],
      "id": "european-discount",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "protective-tomorrow"
      },
      "source": [
        "# Irrelevant transactions\n",
        "Irrelevant = data['StockCode'].astype('str').unique()\n",
        "Irrelevant.sort()\n",
        "print('Irrelevant Transactions: \\n',Irrelevant[::-1][:100])"
      ],
      "id": "protective-tomorrow",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7aLvxTNHjcS"
      },
      "source": [
        "def pre_processing(df):\n",
        "  df.drop_duplicates(inplace=True)\n",
        "  df = df[~ (df.InvoiceNo.str[0] == 'C')]\n",
        "  df.dropna(inplace=True)\n",
        "  df = df[~(df['StockCode'].isin(['POST', 'PADS', 'M', 'DOT', 'C2', 'BANK CHARGES']))]\n",
        "  df = df[(np.abs(scipy.stats.zscore(df['UnitPrice']))<3) & (np.abs(scipy.stats.zscore(df['Quantity']))<5)]\n",
        "  df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'].values)\n",
        "  df['DayOfWeek'] = [i.dayofweek for i in df['InvoiceDate']]\n",
        "  df['MonthName'] = [i.month_name() for i in df['InvoiceDate']]\n",
        "  return df\n",
        "\n",
        "data  = pre_processing(data_orig)"
      ],
      "id": "c7aLvxTNHjcS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "graphic-vampire"
      },
      "source": [
        "## Understanding new insights from the data (1 point)"
      ],
      "id": "graphic-vampire"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "furnished-station"
      },
      "source": [
        "1.  Are there any free items in the data? How many are there?\n",
        "\n",
        "2.  Find the number of transactions per country and visualize using an appropriate plot\n",
        "\n",
        "3.  What is the ratio of customers who are repeat purchasers vs single-time purchasers? Visualize using an appropriate plot.\n",
        "\n",
        "4. Plot heatmap showing unit price per month and day of the week\n",
        "\n",
        "  **Hint:** Month name as index on Y-axis, Day of the week on X-axis\n",
        "\n",
        "5. Find the top 10 customers who bought the most no.of items. Also find the top 10 Items bought by most no.of customers."
      ],
      "id": "furnished-station"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "united-memorial"
      },
      "source": [
        "#### 1. Are there any free items in the data ? How many are there ?"
      ],
      "id": "united-memorial"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "historic-supervisor"
      },
      "source": [
        "data[data.UnitPrice == 0].count()"
      ],
      "id": "historic-supervisor",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "north-power"
      },
      "source": [
        "#### 2. Find the number of transactions per country and visualize"
      ],
      "id": "north-power"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prescribed-speaking"
      },
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "plt.barh(data.Country.value_counts().index, data.Country.value_counts(), log=True)\n",
        "plt.show()"
      ],
      "id": "prescribed-speaking",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "popular-anthropology"
      },
      "source": [
        "#### 3. What is the ratio of customers who are repeat purchasers vs single-time purchasers? Visualize using an appropriate plot"
      ],
      "id": "popular-anthropology"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "portuguese-secretariat"
      },
      "source": [
        "MostRepeat = data.groupby('CustomerID')['InvoiceNo'].nunique().sort_values(ascending=False)\n",
        "rep = MostRepeat[MostRepeat != 1].values\n",
        "nrep = MostRepeat[MostRepeat == 1].values\n",
        "ser = pd.Series([len(rep)/ len(MostRepeat),len(nrep)/len(MostRepeat)], index=['Repeat Customers','One-time Customers'])\n",
        "ser.plot(kind='pie', autopct='%.2f%%').set(ylabel='')\n",
        "plt.suptitle('Top Repeat Customers', fontsize=15)\n",
        "plt.show()"
      ],
      "id": "portuguese-secretariat",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "checked-bishop"
      },
      "source": [
        "#### 4. Plot a heatmap showing unit price per month and day of the week\n",
        "\n",
        "**Hint:** Month name as index on Y-axis, Day of the week on X-axis"
      ],
      "id": "checked-bishop"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfEpDox31huU"
      },
      "source": [
        "data.head(2)"
      ],
      "id": "YfEpDox31huU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "visible-assault"
      },
      "source": [
        "HM_Data = data.pivot_table(index = 'MonthName',columns = 'DayOfWeek', values = 'UnitPrice', aggfunc='sum')\n",
        "plt.figure(figsize = (10,6))\n",
        "sns.heatmap(HM_Data, cmap = 'vlag').set(xlabel='', ylabel='')\n",
        "plt.title('Sales Value per Month and Day of Week', fontsize = 15)\n",
        "plt.show()"
      ],
      "id": "visible-assault",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "straight-doctor"
      },
      "source": [
        "#### 5. Find the top 10 customers who bought the most no.of items. Also find the top 10 Items bought by most no. of customers."
      ],
      "id": "straight-doctor"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "municipal-blair"
      },
      "source": [
        "Top10Customers = data.groupby('CustomerID').agg({\"Quantity\":\"sum\"}).sort_values('Quantity', ascending=False).iloc[:10]\n",
        "print(Top10Customers)"
      ],
      "id": "municipal-blair",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR1luwnRCPPS"
      },
      "source": [
        "top10Items = data.StockCode.value_counts(sort=True, ascending=False)[:10]\n",
        "print(top10Items)"
      ],
      "id": "JR1luwnRCPPS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "royal-chancellor"
      },
      "source": [
        "## Feature Engineering and Transformation (2 points)"
      ],
      "id": "royal-chancellor"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dietary-willow"
      },
      "source": [
        "### Create new features to uncover better insights and drop the unwanted columns\n",
        "\n",
        "* Create a new column which represents Total amount spent by each customer\n",
        "\n",
        "    **Hint:** Quantity * UnitPrice\n",
        "\n",
        "* Customer IDs are seen to be repeated. Maintain unique customer IDs by grouping and summing up all possible observations per customer.\n",
        "\n",
        "    **Hint:** [pandas.groupby.agg](https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.core.groupby.DataFrameGroupBy.agg.html)\n",
        "\n",
        "**Note:** Perform the above operations in function, to reuse and apply the same for test data"
      ],
      "id": "dietary-willow"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWLK28ubLSpN"
      },
      "source": [
        "def feature_engineering(df):\n",
        "  # total spend by each customer\n",
        "  df['TotalSpend'] = df['Quantity'] * df['UnitPrice']\n",
        "  # unique customers\n",
        "  data_grouped = df.groupby('CustomerID')[['Quantity','TotalSpend']].agg('sum').reset_index()\n",
        "  # maximum visits on day of week by each customer\n",
        "  data_grouped['DayOfWeek'] = df.groupby('CustomerID')['DayOfWeek'].agg('max').reset_index()['DayOfWeek']\n",
        "  return data_grouped"
      ],
      "id": "gWLK28ubLSpN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKp8pLfY0n72"
      },
      "source": [
        "data_grouped = feature_engineering(data)"
      ],
      "id": "aKp8pLfY0n72",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "respected-empire"
      },
      "source": [
        "### Scale the data\n",
        "\n",
        "Apply `StandardScaler` on the features."
      ],
      "id": "respected-empire"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "requested-crystal"
      },
      "source": [
        "# Select the features\n",
        "X = data_grouped.iloc[:, 1:]"
      ],
      "id": "requested-crystal",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "missing-capitol"
      },
      "source": [
        "# Feature Scaling\n",
        "\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)\n",
        "X.shape, X.min(), X.max()"
      ],
      "id": "missing-capitol",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smooth-florist"
      },
      "source": [
        "## Clustering ( 5 points)"
      ],
      "id": "smooth-florist"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn1qD44PI0H_"
      },
      "source": [
        "### Apply k-means algorithm to identify a specific number of clusters\n",
        "\n",
        "\n",
        "* Fit the k-means model\n",
        "\n",
        "* Extract and store the cluster centroids\n",
        "\n",
        "Below are the parameters for k-means, which are helpful\n",
        "\n",
        "**n_clusters** is no. of clusters specified\n",
        "\n",
        "**k-means++** is a random initialization method for centroids to avoid random initialisation trap\n",
        "\n",
        "**max_iter** is max no of iterations defined when k-means is running\n",
        "\n",
        "**n_init** is no. of times k-means will run with different initial centroids\n",
        "\n",
        "[why-is-k-means-slower-than-random-initialization-k-means](https://stats.stackexchange.com/questions/185396/why-is-k-means-slower-than-random-initialization-k-means/185422)"
      ],
      "id": "rn1qD44PI0H_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "palestinian-parameter"
      },
      "source": [
        "# Fitting k-means to the dataset\n",
        "kmeans = KMeans(n_clusters = 7, init = 'k-means++')\n",
        "y_kmeans = kmeans.fit_predict(X)"
      ],
      "id": "palestinian-parameter",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reasonable-burke"
      },
      "source": [
        "#### Find the optimal number of clusters (K) by using the [Elbow method](https://pythonprogramminglanguage.com/kmeans-elbow-method/).\n",
        "\n",
        "Use the optimal no. of clusters and store the cluster centroids"
      ],
      "id": "reasonable-burke"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exciting-senator"
      },
      "source": [
        "# Using the Elbow method to find the optimal no.of clusters\n",
        "inertia = []\n",
        "clusters, centroids = {}, {}\n",
        "\n",
        "for i in range(2,15):\n",
        "    kmeans = KMeans(n_clusters = i, init ='k-means++',max_iter=300,n_init=10)\n",
        "    kmeans.fit(X)\n",
        "    clusters[i] = kmeans.fit_predict(X)\n",
        "    centroids[i] = kmeans.cluster_centers_\n",
        "    inertia.append(kmeans.inertia_)"
      ],
      "id": "exciting-senator",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "architectural-gross"
      },
      "source": [
        "# plot the clusters vs inertia\n",
        "plt.plot(range(2,15) , inertia)\n",
        "plt.title('Elbow Method')\n",
        "plt.xlabel('Clusters')\n",
        "plt.ylabel('Inertia')\n",
        "plt.show()"
      ],
      "id": "architectural-gross",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "interesting-delta"
      },
      "source": [
        "# Optimal cluster at 6, so choosing centroids\n",
        "centroids_optimal = centroids[6]\n",
        "clusters_optimal = clusters[6]"
      ],
      "id": "interesting-delta",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q7nKnfVK_Yj"
      },
      "source": [
        "### Apply DBSCAN algorithm for clustering\n",
        "\n",
        "- Compare the results of clusters from k-means and DBSCAN\n"
      ],
      "id": "0q7nKnfVK_Yj"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP1PwIKeLA8u"
      },
      "source": [
        "# Perform DBSCAN on data\n",
        "from sklearn.cluster import DBSCAN\n",
        "dbscan = DBSCAN(eps=0.24, min_samples=7)\n",
        "dbscan.fit(X)\n",
        "db_labels = dbscan.labels_\n",
        "print(\"Unique clusters in data: \", np.unique(db_labels))"
      ],
      "id": "GP1PwIKeLA8u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FarGC20zgjHj"
      },
      "source": [
        "### Analyze the clusters\n",
        "\n",
        "\n",
        "- consider two features and visualize the clusters with different colors using the predicted cluster centers.\n",
        "\n",
        "  **Hint:** 2D plot\n",
        "\n",
        "- consider three features and visualize the clusters with different colors using the predicted cluster centers.\n",
        "\n",
        "  **Hint:** [3D plot](https://matplotlib.org/stable/gallery/mplot3d/scatter3d.html\n",
        ")"
      ],
      "id": "FarGC20zgjHj"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi0-h4zbgjHk"
      },
      "source": [
        "# Visualising the clusters considering Unit Price and Quantity\n",
        "plt.scatter(X[clusters_optimal == 0, 0], X[clusters_optimal == 0, 1], c = 'red', label = 'cluster 1')\n",
        "plt.scatter(X[clusters_optimal == 1, 0], X[clusters_optimal == 1, 1], c = 'blue', label = 'cluster 2')\n",
        "plt.scatter(X[clusters_optimal == 2, 0], X[clusters_optimal == 2, 1], c = 'green', label = 'cluster 3')\n",
        "plt.scatter(X[clusters_optimal == 3, 0], X[clusters_optimal == 3, 1], c = 'magenta', label = 'cluster 4')\n",
        "plt.scatter(X[clusters_optimal == 4, 0], X[clusters_optimal == 4, 1], c = 'k', label = 'cluster 5')\n",
        "plt.scatter(X[clusters_optimal == 5, 0], X[clusters_optimal == 5, 1], c = 'brown', label = 'cluster 6')\n",
        "plt.scatter(centroids_optimal[:, 0], centroids_optimal[:, 1], s = 100, c = 'yellow', label = 'Centroids')\n",
        "plt.title('Clusters of customers')\n",
        "plt.xlabel('Quantity')\n",
        "plt.ylabel('TotalSpend')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "wi0-h4zbgjHk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDbJ5dQLatOl"
      },
      "source": [
        "From the above plot, we can see the clusters are separable in 2D plot using scaled features"
      ],
      "id": "SDbJ5dQLatOl"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Muwv_0BHOS02"
      },
      "source": [
        "# Visualising all the clusters in 3D\n",
        "\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "ax = plt.axes(projection='3d')\n",
        "ax.scatter(X[clusters_optimal == 0, 0], X[clusters_optimal == 0, 1], X[clusters_optimal == 0, 2], c = 'red', label = 'cluster 1')\n",
        "ax.scatter(X[clusters_optimal == 1, 0], X[clusters_optimal == 1, 1], X[clusters_optimal == 1, 2], c = 'blue', label = 'cluster 2')\n",
        "ax.scatter(X[clusters_optimal == 2, 0], X[clusters_optimal == 2, 1], X[clusters_optimal == 2, 2], c = 'green', label = 'cluster 3')\n",
        "ax.scatter(X[clusters_optimal == 3, 0], X[clusters_optimal == 3, 1], X[clusters_optimal == 3, 2], c = 'magenta', label = 'cluster 4')\n",
        "ax.scatter(X[clusters_optimal == 4, 0], X[clusters_optimal == 4, 1], X[clusters_optimal == 4, 2], c = 'k', label = 'cluster 5')\n",
        "ax.scatter(X[clusters_optimal == 5, 0], X[clusters_optimal == 5, 1], X[clusters_optimal == 5, 2], c = 'brown', label = 'cluster 6')\n",
        "ax.set_xlabel(\"Quantity\")\n",
        "ax.set_ylabel(\"TotalSpend\")\n",
        "ax.set_zlabel(\"DayOfWeek\")\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "id": "Muwv_0BHOS02",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zef_pWaE20pP"
      },
      "source": [
        "### Train a supervised algorithm on clustered data\n",
        "\n",
        "This will allow us to predict cluster numbers (label) for each test data instance\n",
        "\n",
        "* Create labelled data with k-means cluster labels\n",
        "  \n",
        "  **Hint**: [`kmeans.labels_`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
        ")\n",
        "* Split the data into train and validation sets\n",
        "* Train a supervised algorithm on the train data\n",
        "* Find the accuracy of the model using validation data\n",
        "* Use this model to predict the labels for the Test data (note: Test data is provided separately below)"
      ],
      "id": "zef_pWaE20pP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zztS3U3y3ZvU"
      },
      "source": [
        "data_grouped['Label'] = clusters[6]\n",
        "data_grouped.head(3)"
      ],
      "id": "zztS3U3y3ZvU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLCHn9-j5ooT"
      },
      "source": [
        "features = data_grouped.iloc[:,1:-1]\n",
        "labels = data_grouped.iloc[:,-1]\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.25,random_state=42)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "id": "YLCHn9-j5ooT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU2QrFi06aKA"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train,y_train)\n",
        "rf.score(X_test, y_test)"
      ],
      "id": "RU2QrFi06aKA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUWhJeDpzh7Z"
      },
      "source": [
        "### Evaluation of Test Data\n",
        "\n",
        "* Format the test data in the same format as the train data.\n",
        "* predict it with trained supervised ML model"
      ],
      "id": "cUWhJeDpzh7Z"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G16_wae9zjv7"
      },
      "source": [
        "test = pd.read_csv(\"Online_Retail_Test.csv\")\n",
        "test.head(3)"
      ],
      "id": "G16_wae9zjv7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU4cC3qWKyCi"
      },
      "source": [
        "test_preprocessed = pre_processing(test)\n",
        "df_test = feature_engineering(test_preprocessed)\n",
        "df_test.head(2)"
      ],
      "id": "WU4cC3qWKyCi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGO4eCmAMA7P"
      },
      "source": [
        "df_test.isna().sum()"
      ],
      "id": "QGO4eCmAMA7P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_PzIW2QDizH"
      },
      "source": [
        "test_features = df_test.iloc[:,1:]\n",
        "rf.predict(test_features)"
      ],
      "id": "R_PzIW2QDizH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAXIXD9S7Jxx"
      },
      "source": [
        "### Report Analysis\n",
        "\n",
        "- Discuss the pros and cons of removing the missing values vs replacing with the mean values\n",
        "- Based on the visualization of clusters, comment on the difference in buying patterns of each cluster\n",
        "- What others methods could be used to determine the optimal no. of clusters?"
      ],
      "id": "ZAXIXD9S7Jxx"
    }
  ]
}