{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFBl3DsqB3AE"
      },
      "source": [
        "# Advanced Certification Program in Computational Data Science\n",
        "\n",
        "##  A program by IISc and TalentSprint\n",
        "\n",
        "### Mini Project Notebook: Urban Traffic Flow Prediction using Graph Convolution Network - LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maritime-miami"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95F1ym6qB8VU"
      },
      "source": [
        "At the end of the experiment, you will be able to :\n",
        "\n",
        "* forecast traffic flow using Graph Convolutional Network and LSTM\n",
        "* understand the graph structured data and implement the forecasting model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8aczZmzvXTc"
      },
      "source": [
        "## Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6FK1IfmASS7"
      },
      "source": [
        "Accurate and real-time traffic forecasting plays an important role in the Intelligent Traffic System and is important for\n",
        "\n",
        "- urban traffic planning,\n",
        "- traffic management, and\n",
        "- traffic control.\n",
        "\n",
        "Traffic forecasting is a challenging issue because of the constraints of the urban road network topological structure and the law of dynamic change with time (spatial dependence and temporal dependence). To capture the spatial and temporal dependence simultaneously, a neural network-based traffic forecasting method called the temporal graph convolutional network (T-GCN) model is very useful. It is a combination of the graph convolutional network (GCN) and gated recurrent unit (GRU).\n",
        "\n",
        "- Specifically, the GCN is used to learn complex topological structures to capture spatial dependence and the gated recurrent unit is used to learn dynamic changes of traffic data to capture temporal dependence. Then, the T-GCN model is employed to traffic forecasting based on the urban road network. T-GCN model can obtain the spatio-temporal correlation from traffic data and the predictions outperform state-of-art baselines on real-world traffic datasets.\n",
        "\n",
        "Reference: https://arxiv.org/abs/1811.05320"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgx1PkHfCDyJ"
      },
      "source": [
        "## Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX9HlPtwAV7C"
      },
      "source": [
        "Urban Traffic Prediction from Spatio-Temporal Data Using Deep Meta Learning.\n",
        "\n",
        "This traffic dataset contains traffic information collected from loop detectors in the highway of Los Angeles County (Jagadish et al., 2014). This dataset contains traffic speeds from Mar-1 to Mar-7, 2012 of 207 sensors, recorded every 5 minutes.  There are 2016 observations (timesteps) of speed records over 207 sensors. Speeds are recorded every 5 minutes. This means that, for a single hour, you will have 12 observations. Similarly, a single day will contain 288 (12x24) observations. Overall, the data consists of speeds recorded every 5 minutes over 207 for 7 days (12X24X7).\n",
        "\n",
        "Data Source:\n",
        "https://github.com/lehaifeng/T-GCN/tree/master/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih-oasWmdZul"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGCdlQfY8jlN"
      },
      "source": [
        "Forecasting urban traffic flow using spatio-temporal data with combined Graph Convolution + LSTM model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "operating-latter"
      },
      "source": [
        "## Grading = 10 Points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JVCoY4Jjf0xK"
      },
      "outputs": [],
      "source": [
        "#@title Download dataset\n",
        "!wget -qq https://raw.githubusercontent.com/lehaifeng/T-GCN/master/data/los_adj.csv\n",
        "!wget -qq https://raw.githubusercontent.com/lehaifeng/T-GCN/master/data/los_speed.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abstract-stocks"
      },
      "source": [
        "### Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8FER60G83X_"
      },
      "outputs": [],
      "source": [
        "!pip -qq install stellargraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM7iURQG8lYI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, RepeatVector, TimeDistributed\n",
        "import stellargraph as sg\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGwCf2K58oi0"
      },
      "outputs": [],
      "source": [
        "# from stellargraph.layer import GCN\n",
        "# from stellargraph.mapper import FullBatchNodeGenerator, PaddedGraphGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VavwcIp7oV_W"
      },
      "source": [
        "### Data loading and preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJH3nTz5gKVk"
      },
      "outputs": [],
      "source": [
        "sensor_dist_adj = pd.read_csv(\"/content/los_adj.csv\",header=None)\n",
        "speed_data = pd.read_csv(\"/content/los_speed.csv\").T\n",
        "sensor_dist_adj = np.mat(sensor_dist_adj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riO_91D4TfB4"
      },
      "outputs": [],
      "source": [
        "speed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YXQdjK3S_db"
      },
      "outputs": [],
      "source": [
        "sensor_dist_adj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMhUZIl98zlM"
      },
      "outputs": [],
      "source": [
        "num_nodes, time_len = speed_data.shape\n",
        "print(\"No. of sensors:\", num_nodes, \"\\nNo of timesteps:\", time_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qatm6YyZWItf"
      },
      "outputs": [],
      "source": [
        "sensor_dist_adj.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eO9s5KB-Vaz"
      },
      "outputs": [],
      "source": [
        "speed_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-FKMF5o1q4S"
      },
      "source": [
        "#### Plotting the time series of 10 sensors data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plcr6i8n1Acz"
      },
      "outputs": [],
      "source": [
        "speed_data.T.iloc[:,:10].plot(figsize=(14,5))\n",
        "plt.ylabel('sales')\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwKVp-GiAiP0"
      },
      "source": [
        "#### Create and draw the graph of adjacency of matrix\n",
        "\n",
        "Hint: [link](https://towardsdatascience.com/graph-coloring-with-networkx-88c45f09b8f4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7-Yolm7BMB7"
      },
      "outputs": [],
      "source": [
        "def show_graph_with_labels(adjacency_matrix):\n",
        "    rows, cols = np.where(adjacency_matrix > 0)\n",
        "    edges = zip(rows.tolist(), cols.tolist())\n",
        "    gr = nx.Graph()\n",
        "    gr.add_edges_from(edges)\n",
        "    nx.draw(gr, node_size=10)#, labels=mylabels, with_labels=True)\n",
        "    plt.show()\n",
        "\n",
        "show_graph_with_labels(sensor_dist_adj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po7JgKeZobCd"
      },
      "source": [
        "### Preprocessing and train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IezodGpF-oKp"
      },
      "outputs": [],
      "source": [
        "def train_test_split(data, train_portion):\n",
        "    time_len = data.shape[1]\n",
        "    train_size = int(time_len * train_portion)\n",
        "    train_data = np.array(data.iloc[:,:train_size])\n",
        "    test_data = np.array(data.iloc[:,train_size:])\n",
        "    return train_data, test_data\n",
        "train_rate = 0.8\n",
        "train_data, test_data = train_test_split(speed_data, train_rate)\n",
        "print(\"Train data: \", train_data.shape)\n",
        "print(\"Test data: \", test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnR4MYHm-sdv"
      },
      "outputs": [],
      "source": [
        "def scale_data(train_data, test_data):\n",
        "    max_speed = train_data.max()\n",
        "    min_speed = train_data.min()\n",
        "    train_scaled = (train_data - min_speed) / (max_speed - min_speed)\n",
        "    test_scaled = (test_data - min_speed) / (max_speed - min_speed)\n",
        "    return train_scaled, test_scaled\n",
        "train_scaled, test_scaled = scale_data(train_data, test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqJqtvoGThWR"
      },
      "source": [
        "#### Prepare Time series data\n",
        "\n",
        "\n",
        "Aim is to use 50 minutes of historical speed observations to predict the speed in future (1 hour ahead)\n",
        "\n",
        "* Choose windows of 10 historical observations i.e. 5 * 10 = 50 minutes (`seq_len`) for each segment as the input and use it to predict the speed after 5 * 12 = 60 minutes (target) using the sliding window approach.\n",
        "\n",
        "**Note:**\n",
        "The below parameters\n",
        "-  `seq_len` is the size of the past window of information.\n",
        "- `pre_len` is future prediction ( 1 hour in future = 12 * 5 minutes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8fXzUTXeZxg"
      },
      "source": [
        "Steps:\n",
        "\n",
        "* Prepare the data to be fed into an LSTM. The LSTM model learns a function that maps a **sequence of past observations as input to an output observation**, so the sequence of observations must be transformed into multiple examples from which the LSTM can learn.\n",
        "\n",
        "* Choose to use 50 minutes of historical speed observations to predict the speed in future (eg. 1 hour ahead). First reshape the timeseries data into windows of 10 historical observations for each segment as the input and the speed 60 minutes later as the prediction label. This can be performed using a sliding window approach:\n",
        "\n",
        "    - Starting from the beginning of the timeseries, we take the first 10 speed records as the 10 input features and the speed 12 timesteps head (60 minutes) as the speed we want to predict.\n",
        "\n",
        "    - Shift the timeseries by one timestep and take the 10 observations from the current point as the input features and the speed one hour ahead as the output to predict.\n",
        "\n",
        "    - Keep shifting by 1 timestep and picking the 10 timestep window from the current time as input feature and the speed one hour ahead of the 10th timestep as the output to predict, for the entire data.\n",
        "\n",
        "  *Note: The above steps are done for each sensor.*\n",
        "\n",
        "The function below returns the above transformed timeseries data for the model to train on. The parameter seq_len is the size of the past window of information. The pre_len is how far in the future does the model need to learn to predict.\n",
        "\n",
        "Each **training observation** is 10 historical speeds **(seq_len).**\n",
        "\n",
        "Each **training prediction** is the speed 60 minutes later **(pre_len).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IZJ2Ivl-0DZ"
      },
      "outputs": [],
      "source": [
        "seq_len = 10\n",
        "pre_len = 12\n",
        "def sequence_data_preparation(seq_len, pre_len, train_data, test_data):\n",
        "    trainX, trainY, testX, testY = [], [], [], []\n",
        "    for i in range(train_data.shape[1] - int(seq_len + pre_len - 1)):\n",
        "        a = train_data[:, i : i + seq_len + pre_len]\n",
        "        trainX.append(a[:,:seq_len])\n",
        "        trainY.append(a[:,-1])\n",
        "\n",
        "    for i in range(test_data.shape[1] - int(seq_len + pre_len - 1)):\n",
        "        b = test_data[:,i : i + seq_len + pre_len]\n",
        "        testX.append(b[:,:seq_len])\n",
        "        testY.append(b[:,-1])\n",
        "    return np.array(trainX), np.array(trainY), np.array(testX), np.array(testY)\n",
        "\n",
        "trainX, trainY, testX, testY = sequence_data_preparation(seq_len, pre_len, train_scaled, test_scaled)\n",
        "trainX.shape, trainY.shape, testX.shape, testY.shape,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK6eeqi1VMPJ"
      },
      "source": [
        "### Build and Train the LSTM model and plot the loss results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZ2ud77OSh1G"
      },
      "outputs": [],
      "source": [
        "inp = Input(shape=(207, 10))\n",
        "x = LSTM(200, activation='tanh')(inp)\n",
        "x = RepeatVector(200)(x)\n",
        "x = LSTM(200, activation='tanh')(x)\n",
        "out = Dense(207)(x)\n",
        "model_lstm = Model(inp, out)\n",
        "model_lstm.compile(optimizer='adam', loss='mse')\n",
        "model_lstm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyAlQBa-TWPO"
      },
      "outputs": [],
      "source": [
        "hist = model_lstm.fit(x = trainX,y= trainY, epochs=10, validation_data=(testX, testY))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfD7AOLxVapg"
      },
      "outputs": [],
      "source": [
        "sg.utils.plot_history(hist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN9rDfdGBcIV"
      },
      "source": [
        "### StellarGraph Graph Convolution and LSTM model ( 3 points)\n",
        "\n",
        "In order to use the model, we need:\n",
        "\n",
        "* An **N by N** adjacency matrix, which describes the distance relationship between the N sensors,\n",
        "\n",
        "* An **N by T** feature matrix, which describes the ($f_1, .., f_T$) speed records over T timesteps for the N sensors.\n",
        "\n",
        "Arguments of GCN_LSTM:\n",
        "  - seq_len: No. of LSTM cells\n",
        "\n",
        "  - adj: unweighted/weighted adjacency matrix\n",
        "\n",
        "  - gc_layer_sizes (list of int): Output sizes of Graph Convolution  layers in the stack.\n",
        "\n",
        "  - lstm_layer_sizes (list of int): Output sizes of LSTM layers in the stack.\n",
        "\n",
        "  - gc_activations (list of str or func): Activations applied to each layer's output.\n",
        "\n",
        "  - lstm_activations (list of str or func): Activations applied to each layer's output; defaults to ``['tanh', ..., 'tanh']``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m28PLceIWQ0y"
      },
      "outputs": [],
      "source": [
        "from stellargraph.layer import GCN_LSTM\n",
        "GCN_LSTM?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_DPDBhr-7ER"
      },
      "outputs": [],
      "source": [
        "gcn_lstm = GCN_LSTM(\n",
        "    seq_len=seq_len,\n",
        "    adj=sensor_dist_adj,\n",
        "    gc_layer_sizes=[16, 10],\n",
        "    gc_activations=[\"relu\", \"relu\"],\n",
        "    lstm_layer_sizes=[200, 200],\n",
        "    lstm_activations=[\"tanh\", \"tanh\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tv6x-20Z_vCm"
      },
      "outputs": [],
      "source": [
        "x_input, x_output = gcn_lstm.in_out_tensors()\n",
        "model = Model(inputs=x_input, outputs=x_output)\n",
        "model.compile(optimizer=\"adam\", loss=\"mae\", metrics=[\"mse\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBFA6IH0_F-_"
      },
      "outputs": [],
      "source": [
        "history = model.fit(trainX, trainY, epochs=100, batch_size=60, validation_data=(testX, testY))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9W9rgwu_5vU"
      },
      "outputs": [],
      "source": [
        "sg.utils.plot_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8owfap2IFzb"
      },
      "outputs": [],
      "source": [
        "ythat = model.predict(trainX)\n",
        "yhat = model.predict(testX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd9lHPk9cuJv"
      },
      "outputs": [],
      "source": [
        "trainX.shape, testX.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWZdCIJrH-DT"
      },
      "source": [
        "#### Rescale values\n",
        "Rescale the predicted values to the original value range of the timeseries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHNkCRn8H8bl"
      },
      "outputs": [],
      "source": [
        "## Rescale values\n",
        "max_speed = train_data.max()\n",
        "min_speed = train_data.min()\n",
        "\n",
        "## actual train and test values\n",
        "train_rescref = np.array(trainY * max_speed)\n",
        "test_rescref = np.array(testY * max_speed)\n",
        "## Rescale model predicted values\n",
        "train_rescpred = np.array((ythat) * max_speed)\n",
        "test_rescpred = np.array((yhat) * max_speed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pdS3jmngMsX"
      },
      "outputs": [],
      "source": [
        "test_rescref.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWLbMdwMc5nF"
      },
      "outputs": [],
      "source": [
        "onetest_sample = testX[0,].reshape(1,207,10)\n",
        "print(onetest_sample.shape)\n",
        "onesample_pred = model.predict(onetest_sample)\n",
        "onesample_pred.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNBf9tqwLPrf"
      },
      "source": [
        "### Plot the predictions and Loss of each sensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-AO8oFWHXAB"
      },
      "outputs": [],
      "source": [
        "##all test result visualization\n",
        "fig1 = plt.figure(figsize=(15, 8))\n",
        "#    ax1 = fig1.add_subplot(1,1,1)\n",
        "a_pred = test_rescpred[:, 5]\n",
        "a_true = test_rescref[:, 5]\n",
        "plt.plot(a_pred, \"r-\", label=\"prediction\")\n",
        "plt.plot(a_true, \"b-\", label=\"true\")\n",
        "plt.xlabel(\"time\")\n",
        "plt.ylabel(\"speed\")\n",
        "plt.legend(loc=\"best\", fontsize=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzZJ6aiA2ggy"
      },
      "source": [
        "Error plotting for all the sensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plGXq3qhHw8k"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "mse_sensors, mae_sensors = [],[]\n",
        "for sensor in range(test_rescpred.shape[1]):\n",
        "  a_pred = test_rescpred[:, sensor]\n",
        "  a_true = test_rescref[:, sensor]\n",
        "  mse_sensors.append(mean_squared_error(a_true, a_pred))\n",
        "  mae_sensors.append(mean_absolute_error(a_true, a_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlVJC5mT3SOJ"
      },
      "outputs": [],
      "source": [
        "# mse bar plot\n",
        "plt.bar(range(207),mse_sensors)\n",
        "plt.xlabel(\"Sensors\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-yzyffZ4IaU"
      },
      "outputs": [],
      "source": [
        "# mae bar plot\n",
        "plt.bar(range(207),mae_sensors)\n",
        "plt.xlabel(\"Sensors\")\n",
        "plt.ylabel(\"MAE\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQcnE2K1l839"
      },
      "source": [
        "#### Report Analysis\n",
        "\n",
        "  * Discuss: Why is this called a spatio-temporal problem?\n",
        "\n",
        "  * Discuss: In what way is GCN-LSTM more useful for the traffic prediction task than LSTM?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
